{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2988678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: /home/rudy/Documents/carla-dataset-runner/PythonAPI/carla to the Path\n",
      "Added: /home/rudy/Documents/carla-dataset-runner/PythonAPI/carla/dist/carla-0.9.11-py3.7-linux-x86_64.egg to the Path\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import settings\n",
    "\n",
    "initial_path = set(sys.path)\n",
    "sys.path.append(settings.CARLA_EGG_PATH)\n",
    "\n",
    "# ADD \n",
    "try:\n",
    "    sys.path.append(os.path.abspath('.') + '/PythonAPI/carla')\n",
    "except IndexError:\n",
    "    pass\n",
    "\n",
    "new_paths = set(sys.path) - initial_path\n",
    "for path in new_paths:\n",
    "    print(f\"Added: {path} to the Path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "566c76b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import cv2\n",
    "from carla import ColorConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "144d62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth2grayscale(arr):\n",
    "    arr[arr == 1000] = 0\n",
    "    normalized_depth = cv2.normalize(arr, arr, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "    normalized_depth = np.stack((normalized_depth,)*3, axis=-1)  # Grayscale into 3 channels\n",
    "    return normalized_depth\n",
    "\n",
    "\n",
    "def labels_to_cityscapes_palette(arr):\n",
    "    classes = {\n",
    "        0: [0, 0, 0],         # None\n",
    "        1: [70, 70, 70],      # Buildings\n",
    "        2: [100, 40, 40],     # Fences\n",
    "        3: [55, 90, 80],      # Other\n",
    "        4: [220, 20, 60],     # Pedestrians\n",
    "        5: [153, 153, 153],   # Poles\n",
    "        6: [157, 234, 50],    # RoadLines\n",
    "        7: [128, 64, 128],    # Roads\n",
    "        8: [244, 35, 232],    # Sidewalks\n",
    "        9: [107, 142, 35],    # Vegetation\n",
    "        10: [0, 0, 142],      # Vehicles\n",
    "        11: [102, 102, 156],  # Walls\n",
    "        12: [220, 220, 0],    # TrafficSigns\n",
    "        13: [70, 130, 180],   # Sky\n",
    "        14: [81, 0, 81],      # Ground\n",
    "        15: [150, 100, 100],  # Bridge\n",
    "        16: [230, 150, 140],  # RailTrack\n",
    "        17: [180, 165, 180],  # GuardRail\n",
    "        18: [250, 170, 30],   # Traffic Light\n",
    "        19: [110, 190, 160],  # Static\n",
    "        20: [170, 120, 50],   # Dynamic\n",
    "        21: [45, 60, 150],    # Water\n",
    "        22: [145, 170, 100]   # Terrain\n",
    "    }\n",
    "    \n",
    "    result = np.zeros((arr.shape[0], arr.shape[1], 3))\n",
    "    for key, value in classes.items():\n",
    "        result[np.where(arr == key)] = value\n",
    "        \n",
    "    result /= 255.0\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3df42292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: data/test3.hdf5 contains 5 ego runs\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/test3.hdf5\"\n",
    "f = h5py.File(file_path, \"r\")\n",
    "total_run = sum([k.startswith(\"run\") for k in f.keys()])\n",
    "print(f\"The file: {file_path} contains {total_run} ego runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f1142b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = f['run_000_morning']\n",
    "run_rgb = run['rgb']\n",
    "run_depth = run['depth']\n",
    "run_semantic = run['semantic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "55ff40c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 frames for selected record\n"
     ]
    }
   ],
   "source": [
    "timestamps = list(run_rgb.keys())\n",
    "print(f\"{len(timestamps)} frames for selected record\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "70cba311",
   "metadata": {},
   "outputs": [],
   "source": [
    "for timestamp in timestamps:\n",
    "    rgb_image = np.array(run_rgb[timestamp])\n",
    "    depth_map = np.array(run_depth[timestamp])\n",
    "    semantic_map = np.array(run_semantic[timestamp])\n",
    "    cv2.imshow('rgb', rgb_image)\n",
    "    cv2.imshow('depth', depth2grayscale(depth_map))\n",
    "    cv2.imshow('semantic', labels_to_cityscapes_palette(semantic_map))\n",
    "    cv2.waitKey(50)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b9c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-data-collector",
   "language": "python",
   "name": "carla-data-collector"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
